{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, sys, random, requests, uuid, json, argostranslate.package, argostranslate.translate, math\n",
    "from translate import Translator\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_API_KEY = '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'\n",
    "GPT_CHAR_LIMIT = 4096\n",
    "AZURE_KEY = '03d817eef24846c6906dd8427a2d1830'\n",
    "AZURE_CHAR_LIMIT = 50000\n",
    "MYMEMORY_CHAR_LIMIT = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Text by sentences\n",
    "def batch_text(text:str, char_limit:int=1024) -> list[str]:\n",
    "    # Batch Long Sentences by words\n",
    "    def get_max_word_batch(text:str) -> tuple[str,str]:\n",
    "        if len(text) <= char_limit: return (text, '')\n",
    "        last_space = text.rfind(' ', 0, char_limit)\n",
    "        return (text[:last_space], text[last_space:]) if last_space != -1 else (text[:char_limit], text[char_limit:])\n",
    "        \n",
    "    if char_limit <= 2: raise Exception('Invalid Char Limit') \n",
    "    batches, cum_text = [], ''\n",
    "    for sentence in text.split(\".\"):\n",
    "        rmng_sentence = sentence.removeprefix(' ').removesuffix(' ')\n",
    "        while len(rmng_sentence) > char_limit - len(cum_text) - 1:\n",
    "            if cum_text: batches.append(cum_text.removeprefix(' ').removesuffix(' '))\n",
    "            cum_text = ''\n",
    "            if len(rmng_sentence) < char_limit - 1: break\n",
    "            cum_sentence, rmng_sentence = get_max_word_batch(rmng_sentence)\n",
    "            cum_text = cum_sentence + '. '\n",
    "        if rmng_sentence: cum_text += rmng_sentence + '. '\n",
    "    if cum_text:\n",
    "        batches.append(cum_text)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "\n",
    "def generate_random_text(num_sentences=20):\n",
    "    text = \"\"\n",
    "    for _ in range(num_sentences):\n",
    "        sentence = \" \".join(fake.words(nb=random.randint(10, 20))) + \". \"\n",
    "        text += sentence.capitalize()\n",
    "    return text\n",
    "\n",
    "# Generate 100 sentences of random text\n",
    "random_text = generate_random_text()\n",
    "print('Original Text: ' + random_text)\n",
    "print('Results: ')\n",
    "for text in batch_text(random_text, 200):\n",
    "    print(str(len(text)) + ': ' + text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatGPT:\n",
    "    def __init__(self, api_key:str, model:str='gpt-3.5-turbo',messages:list[dict]=[], char_limit:int=2048) -> None:\n",
    "        openai.api_key = api_key\n",
    "        self.model = model\n",
    "        self.messages = messages\n",
    "        self.char_limit = char_limit\n",
    "        self.char_count = 0\n",
    "        \n",
    "    def _add_role(self, role: str, prompt:str):\n",
    "        if role not in ['system', 'user', 'assistant']: raise Exception('Incorrect Role')\n",
    "        self.char_count += len(prompt) \n",
    "        self.messages.append({'role': role, 'content': prompt})\n",
    "    \n",
    "    def add_system_prompt(self, prompt:str):\n",
    "        self._add_role('system', prompt)\n",
    "    \n",
    "    def add_training_prompt(self, question:str, answer:str):\n",
    "        self._add_role('user', question)\n",
    "        self._add_role('assistant', answer)\n",
    "    \n",
    "    def add_question(self, question:str):\n",
    "        self._add_role('user', question)\n",
    "\n",
    "    def get_response(self): \n",
    "        return openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = 'I will provide an interview excerpt between a professor and a parent of a child with iep. At the beginning of which sentences do the speaker change between professor and parent supposing we start with the professor asking? Treating the text as a list of sentences, please list a sequence of numbers, providing only the index (starting from 0) of the resulting sentences with spaces between each index.'\n",
    "test_question = \"Hello, do you like to travel? Yes, a lot! I've been to many places. Out of those, which is your favorite city? London.\"\n",
    "test_answer = '1 3 4'\n",
    "test_prompts = {test_question: test_answer}\n",
    "question = '¿Y qué porción fue? ¿Fue el comienzo del documento o fueron partes específicas del documento? ¿Qué habían traducido? Eran páginas diferentes. Eran desde el principio, la mitad, las páginas intermedias y las páginas finales. Entonces ese IEP fue demasiado confuso. Claro. Bueno, ¿qué está pasando? Y hablé con el administrador del caso. Oh, lo siento, lo vamos a traducir nuevamente. Y tardaron otras tres semanas en enviarlo a traducir. Y tuvieron que pasar dos semanas más para que llegara la interpretación. Y lo que no me gusta es que siempre me lo envían por email, nunca me lo imprimen. Siempre les pido que me lo impriman. Porque no es justo para mí que me traduzcan el IEP y me lo envíen a mi correo electrónico. No me resulta difícil leerlo. Pero tampoco lo es pasar mucho tiempo frente al ordenador. Claro. Entonces ese es el problema que tengo. Está bien. Bien, excelente. Muchas gracias por compartir eso conmigo. Sólo tengo unas preguntas que tienen que ver con la tecnología y ahorita me gustaría preguntarles sobre ciertas cosas respecto a eso. Me preguntaba, ¿cuánto tiempo lleva su hijo en el distrito escolar actual? Ha estado, quiero ver, desde 2017. 17, 18, 19, 20, 21. Hace unos nueve años. Nueve años. ¿Y cada año tienes que pasar por el proceso del IEP? Sí OK. Y a ti te ha ido, ¿cómo ha sido esto? ¿Has tenido problemas cada vez? Si, todos los años he tenido el mismo problema que siempre tardan en mandarlo a traducir, otras dos semanas para que me lo envíen, me lo envían por correo electrónico, tengo que pedir que lo impriman y hacerlo de nuevo juntos porque no estoy satisfecho con las calificaciones.'\n",
    "translated = \"And what portion was it? Was it the beginning of the document or were they specific parts of the document? What did they translate? They were different pages. They were from the beginning, half, middle pages and final pages. So that IEP was too confusing. Sure. Well, what's going on? And I talked to the case manager. Oh, I'm sorry, we're gonna translate it back. And it took another three weeks to send him to translate. And they had to spend two more weeks to get the interpretation. And what I don't like is that they always email me, they never print it. I always ask you to print it. Because it's not fair for me to translate the IEP and send it to my email. It's not hard for me to read it. But it's not a long time in front of the computer either. Sure. So that's the problem I have. All right. Well, excellent. Thank you so much for sharing that with me. I only have a few questions that have to do with technology and I would like to ask you about certain things about that. I was wondering, how long has your son been in the current school district? He's been, I want to see, since 2017. 17, 18, 19, 20, 21. About nine years ago. Nine years. And every year you have to go through the IEP process? Yes, OK. And you're gone, how was this? Have you had problems every time? Yeah, every year I've had the same problem that it always takes to send him to translate, another two weeks to send him to me, send him to me by email, I have to ask them to print him and do it again together because I'm not satisfied with the grades.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Performance, Low Speed, Expensive, Stringent Limitations\n",
    "def get_batched_gpt_response(text:str,system_prompt:str,test_prompts:dict[str,str]={},api_key:str=GPT_API_KEY) -> str:\n",
    "    def gpt_char_limit_check(cum_char_count:int):\n",
    "        if cum_char_count >= GPT_CHAR_LIMIT/2: raise Exception('Exceeded ChatGPT Char Limit')\n",
    "    translation, cum_char_count = '', 0\n",
    "    gpt = ChatGPT(api_key)\n",
    "    cum_char_count += len(system_prompt)\n",
    "    gpt_char_limit_check(cum_char_count)\n",
    "    gpt.add_system_prompt(system_prompt)\n",
    "    for test_question, test_answer in test_prompts.items():\n",
    "        cum_char_count += len(test_question) + len(test_answer)   \n",
    "        gpt_char_limit_check(cum_char_count)\n",
    "        gpt.add_training_prompt(test_question, test_answer)\n",
    "    for batch in batch_text(text, GPT_CHAR_LIMIT/2-cum_char_count):\n",
    "        gpt.add_question(batch)\n",
    "        translation += gpt.get_response().get('choices')[0].get('message').get('content')\n",
    "    return translation\n",
    "get_batched_gpt_response(translated,system_prompt,test_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Performance and Speed, Free up to 2M Chars\n",
    "def get_azure_translation(text:str, api_key=AZURE_KEY) -> str:\n",
    "    translation = ''\n",
    "    key = api_key\n",
    "    endpoint = \"https://api.cognitive.microsofttranslator.com/\"\n",
    "    location = \"eastus\"\n",
    "    path = '/translate'\n",
    "    constructed_url = endpoint + path\n",
    "    params = {'api-version': '3.0','from': 'es','to': ['en']}\n",
    "    headers = {'Ocp-Apim-Subscription-Key': key,'Ocp-Apim-Subscription-Region': location,'Content-type': 'application/json','X-ClientTraceId': str(uuid.uuid4())}\n",
    "    for batch in batch_text(text, AZURE_CHAR_LIMIT):\n",
    "        body = [{'text': batch}]\n",
    "        request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "        translation += request.json()[0].get('translations')[0].get('text')\n",
    "    return translation\n",
    "#get_azure_translation(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast and Free, Stringent Limitations\n",
    "def get_mymemory_translation(text:str) -> str:\n",
    "    translation = ''\n",
    "    for batch in batch_text(text, 500):\n",
    "        translation += Translator(provider='mymemory',from_lang='es',to_lang='en').translate(batch)\n",
    "    return translation\n",
    "#get_mymemory_translation(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fastest and Native, Reduced Performance\n",
    "def get_offline_translation(text:str) -> str:\n",
    "    return argostranslate.translate.translate(text,'es', 'en')\n",
    "#get_offline_translation(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "# Thanks GPT\n",
    "def split_mp3(input_file_path:str, max_file_size_mb:int=20, output_folder:str=\"output\"):\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_clip = AudioFileClip(input_file_path)\n",
    "    total_duration = audio_clip.duration  # Total duration of the audio file in seconds\n",
    "    \n",
    "    # Assume an average bitrate for MP3 files (in bps)\n",
    "    # This may need to be adjusted based on the file's actual bitrate\n",
    "    avg_bitrate = 128000  # 128 kbps\n",
    "\n",
    "    # Calculate the maximum duration of each audio chunk in seconds\n",
    "    max_chunk_duration = (max_file_size_mb * 8 * 1024 * 1024) / avg_bitrate\n",
    "    \n",
    "    # Calculate the number of chunks that will be created\n",
    "    number_of_chunks = math.ceil(total_duration / max_chunk_duration)\n",
    "    \n",
    "    # Split the audio file into chunks\n",
    "    for i in range(number_of_chunks):\n",
    "        start_time = i * max_chunk_duration\n",
    "        end_time = min((i + 1) * max_chunk_duration, total_duration)\n",
    "        chunk = audio_clip.subclip(start_time, end_time)\n",
    "        \n",
    "        # Generate the output file path\n",
    "        output_file_path = os.path.join(output_folder, f\"chunk_{i+1}.mp3\")\n",
    "        \n",
    "        # Write the audio chunk to a file\n",
    "        chunk.write_audiofile(output_file_path, bitrate='128k')\n",
    "        \n",
    "        print(f\"Chunk {i+1}/{number_of_chunks} has been created: {output_file_path}\")\n",
    "    \n",
    "    audio_clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = VideoFileClip('pm.mp4')\n",
    "video.audio.write_audiofile('pm.mp3')\n",
    "split_mp3('pm.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"output\"\n",
    "\n",
    "# List all the files in the output directory\n",
    "file_list = os.listdir(output_folder)\n",
    "transcribed_text = ''\n",
    "response = None\n",
    "\n",
    "# Loop through the files and read them with MoviePy\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith(\".mp3\"):  # Check if the file is an MP3\n",
    "        file_path = os.path.join(output_folder, file_name)\n",
    "        response = openai.Audio.transcribe('whisper-1', file=open(file_path,'rb'),api_key=GPT_API_KEY)\n",
    "        transcribed_text += response.get('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_text = get_offline_translation(transcribed_text)\n",
    "with open('parent_meeting.txt','w') as f:\n",
    "    f.write(dual_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_batched_gpt_response(dual_text, system_prompt, test_prompts)\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
