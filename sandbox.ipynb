{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, sys, random, requests, uuid, json, argostranslate.package, argostranslate.translate, math\n",
    "from translate import Translator\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_API_KEY = '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'\n",
    "GPT_CHAR_LIMIT = 4096\n",
    "AZURE_KEY = '03d817eef24846c6906dd8427a2d1830'\n",
    "AZURE_CHAR_LIMIT = 50000\n",
    "MYMEMORY_CHAR_LIMIT = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Text by sentences\n",
    "def batch_text(text:str, char_limit:int=1024) -> list[str]:\n",
    "    # Batch Long Sentences by words\n",
    "    def get_max_word_batch(text:str) -> tuple[str,str]:\n",
    "        if len(text) <= char_limit: return (text, '')\n",
    "        last_space = text.rfind(' ', 0, char_limit)\n",
    "        return (text[:last_space], text[last_space:]) if last_space != -1 else (text[:char_limit], text[char_limit:])\n",
    "        \n",
    "    if char_limit <= 2: raise Exception('Invalid Char Limit') \n",
    "    batches, cum_text = [], ''\n",
    "    for sentence in text.split(\".\"):\n",
    "        rmng_sentence = sentence.removeprefix(' ').removesuffix(' ')\n",
    "        while len(rmng_sentence) > char_limit - len(cum_text) - 1:\n",
    "            if cum_text: batches.append(cum_text.removeprefix(' ').removesuffix(' '))\n",
    "            cum_text = ''\n",
    "            if len(rmng_sentence) < char_limit - 1: break\n",
    "            cum_sentence, rmng_sentence = get_max_word_batch(rmng_sentence)\n",
    "            cum_text = cum_sentence + '. '\n",
    "        if rmng_sentence: cum_text += rmng_sentence + '. '\n",
    "    if cum_text:\n",
    "        batches.append(cum_text)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: Deal cover address myself build tax actually heart according type value while cell parent. Recognize child generation soon weight economic health reduce add word performance history include. Him gun experience exist build against begin sound ground learn see miss brother base away structure early view late analysis. Image no central business way nature military majority career other property enjoy share direction knowledge hold site happy. Economy tough tend air off adult owner majority seat want. Policy wonder produce attention cell floor business hair professional spring house likely weight family perhaps feeling stock choice so interest. Key moment lay allow own heart line trade rate student less main tough house your early any against kid. Fire girl expert evidence modern several although different degree night simply owner free state possible big. Ahead wonder which sort hotel career make a hear wear car data growth community total. If yourself every sound statement wrong offer picture still eat people onto finally positive someone. Never sound say notice organization far agent leader wait wall forward chair reflect age member say sea those none group. Another table interest people side break consumer let better have sing college recognize situation difficult. Sort hotel quality seat son analysis whose happy safe challenge herself consumer you product protect up relate material. Eye green husband for air scene course other him today mind machine anyone have style we. Glass fine later before generation very opportunity mean must make six road throw as traditional. Health them recently health act less great value with this car less pretty financial today probably experience. Argue long health far mouth section unit majority value animal gas fast situation air surface challenge boy. Put help send summer record century your true good middle thought republican adult forward thought phone bar commercial. Care industry public account instead artist draw you including lawyer step speech ten officer bring collection fear manager land concern. Modern own involve any quickly i himself break report add create woman newspaper sister trial yes positive station former. \n",
      "Results: \n",
      "190: Deal cover address myself build tax actually heart according type value while cell parent. Recognize child generation soon weight economic health reduce add word performance history include.\n",
      "126: Him gun experience exist build against begin sound ground learn see miss brother base away structure early view late analysis.\n",
      "184: Image no central business way nature military majority career other property enjoy share direction knowledge hold site happy. Economy tough tend air off adult owner majority seat want.\n",
      "145: Policy wonder produce attention cell floor business hair professional spring house likely weight family perhaps feeling stock choice so interest.\n",
      "104: Key moment lay allow own heart line trade rate student less main tough house your early any against kid.\n",
      "197: Fire girl expert evidence modern several although different degree night simply owner free state possible big. Ahead wonder which sort hotel career make a hear wear car data growth community total.\n",
      "101: If yourself every sound statement wrong offer picture still eat people onto finally positive someone.\n",
      "121: Never sound say notice organization far agent leader wait wall forward chair reflect age member say sea those none group.\n",
      "109: Another table interest people side break consumer let better have sing college recognize situation difficult.\n",
      "120: Sort hotel quality seat son analysis whose happy safe challenge herself consumer you product protect up relate material.\n",
      "187: Eye green husband for air scene course other him today mind machine anyone have style we. Glass fine later before generation very opportunity mean must make six road throw as traditional.\n",
      "111: Health them recently health act less great value with this car less pretty financial today probably experience.\n",
      "108: Argue long health far mouth section unit majority value animal gas fast situation air surface challenge boy.\n",
      "120: Put help send summer record century your true good middle thought republican adult forward thought phone bar commercial.\n",
      "137: Care industry public account instead artist draw you including lawyer step speech ten officer bring collection fear manager land concern.\n",
      "123: Modern own involve any quickly i himself break report add create woman newspaper sister trial yes positive station former. \n"
     ]
    }
   ],
   "source": [
    "fake = Faker()\n",
    "\n",
    "def generate_random_text(num_sentences=20):\n",
    "    text = \"\"\n",
    "    for _ in range(num_sentences):\n",
    "        sentence = \" \".join(fake.words(nb=random.randint(10, 20))) + \". \"\n",
    "        text += sentence.capitalize()\n",
    "    return text\n",
    "\n",
    "# Generate 100 sentences of random text\n",
    "random_text = generate_random_text()\n",
    "print('Original Text: ' + random_text)\n",
    "print('Results: ')\n",
    "for text in batch_text(random_text, 200):\n",
    "    print(str(len(text)) + ': ' + text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatGPT:\n",
    "    def __init__(self, api_key:str, model:str='gpt-3.5-turbo',messages:list[dict]=[], char_limit:int=2048) -> None:\n",
    "        openai.api_key = api_key\n",
    "        self.model = model\n",
    "        self.messages = messages\n",
    "        self.char_limit = char_limit\n",
    "        self.char_count = 0\n",
    "        \n",
    "    def _add_role(self, role: str, prompt:str):\n",
    "        if role not in ['system', 'user', 'assistant']: raise Exception('Incorrect Role')\n",
    "        self.char_count += len(prompt) \n",
    "        self.messages.append({'role': role, 'content': prompt})\n",
    "    \n",
    "    def add_system_prompt(self, prompt:str):\n",
    "        self._add_role('system', prompt)\n",
    "    \n",
    "    def add_training_prompt(self, question:str, answer:str):\n",
    "        self._add_role('user', question)\n",
    "        self._add_role('assistant', answer)\n",
    "    \n",
    "    def add_question(self, question:str):\n",
    "        self._add_role('user', question)\n",
    "\n",
    "    def get_response(self): \n",
    "        return openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = 'I will provide an interview excerpt between a professor and a parent of a child with iep. At the beginning of which sentences do the speaker change between professor and parent supposing we start with the professor asking? Treating the text as a list of sentences, please list a sequence of numbers, providing only the index (starting from 0) of the resulting sentences with spaces between each index.'\n",
    "test_question = \"Hello, do you like to travel? Yes, a lot! I've been to many places. Out of those, which is your favorite city? London.\"\n",
    "test_answer = '1 3 4'\n",
    "test_prompts = {test_question: test_answer}\n",
    "question = '¿Y qué porción fue? ¿Fue el comienzo del documento o fueron partes específicas del documento? ¿Qué habían traducido? Eran páginas diferentes. Eran desde el principio, la mitad, las páginas intermedias y las páginas finales. Entonces ese IEP fue demasiado confuso. Claro. Bueno, ¿qué está pasando? Y hablé con el administrador del caso. Oh, lo siento, lo vamos a traducir nuevamente. Y tardaron otras tres semanas en enviarlo a traducir. Y tuvieron que pasar dos semanas más para que llegara la interpretación. Y lo que no me gusta es que siempre me lo envían por email, nunca me lo imprimen. Siempre les pido que me lo impriman. Porque no es justo para mí que me traduzcan el IEP y me lo envíen a mi correo electrónico. No me resulta difícil leerlo. Pero tampoco lo es pasar mucho tiempo frente al ordenador. Claro. Entonces ese es el problema que tengo. Está bien. Bien, excelente. Muchas gracias por compartir eso conmigo. Sólo tengo unas preguntas que tienen que ver con la tecnología y ahorita me gustaría preguntarles sobre ciertas cosas respecto a eso. Me preguntaba, ¿cuánto tiempo lleva su hijo en el distrito escolar actual? Ha estado, quiero ver, desde 2017. 17, 18, 19, 20, 21. Hace unos nueve años. Nueve años. ¿Y cada año tienes que pasar por el proceso del IEP? Sí OK. Y a ti te ha ido, ¿cómo ha sido esto? ¿Has tenido problemas cada vez? Si, todos los años he tenido el mismo problema que siempre tardan en mandarlo a traducir, otras dos semanas para que me lo envíen, me lo envían por correo electrónico, tengo que pedir que lo impriman y hacerlo de nuevo juntos porque no estoy satisfecho con las calificaciones.'\n",
    "translated = \"And what portion was it? Was it the beginning of the document or were they specific parts of the document? What did they translate? They were different pages. They were from the beginning, half, middle pages and final pages. So that IEP was too confusing. Sure. Well, what's going on? And I talked to the case manager. Oh, I'm sorry, we're gonna translate it back. And it took another three weeks to send him to translate. And they had to spend two more weeks to get the interpretation. And what I don't like is that they always email me, they never print it. I always ask you to print it. Because it's not fair for me to translate the IEP and send it to my email. It's not hard for me to read it. But it's not a long time in front of the computer either. Sure. So that's the problem I have. All right. Well, excellent. Thank you so much for sharing that with me. I only have a few questions that have to do with technology and I would like to ask you about certain things about that. I was wondering, how long has your son been in the current school district? He's been, I want to see, since 2017. 17, 18, 19, 20, 21. About nine years ago. Nine years. And every year you have to go through the IEP process? Yes, OK. And you're gone, how was this? Have you had problems every time? Yeah, every year I've had the same problem that it always takes to send him to translate, another two weeks to send him to me, send him to me by email, I have to ask them to print him and do it again together because I'm not satisfied with the grades.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 7 8 9 10 12 13 14 16 17 18 20 21 23 24 25 27'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Performance, Low Speed, Expensive, Stringent Limitations\n",
    "def get_batched_gpt_response(text:str,system_prompt:str,test_prompts:dict[str,str]={},api_key:str=GPT_API_KEY) -> str:\n",
    "    def gpt_char_limit_check(cum_char_count:int):\n",
    "        if cum_char_count >= GPT_CHAR_LIMIT/2: raise Exception('Exceeded ChatGPT Char Limit')\n",
    "    translation, cum_char_count = '', 0\n",
    "    gpt = ChatGPT(api_key)\n",
    "    cum_char_count += len(system_prompt)\n",
    "    gpt_char_limit_check(cum_char_count)\n",
    "    gpt.add_system_prompt(system_prompt)\n",
    "    for test_question, test_answer in test_prompts.items():\n",
    "        cum_char_count += len(test_question) + len(test_answer)   \n",
    "        gpt_char_limit_check(cum_char_count)\n",
    "        gpt.add_training_prompt(test_question, test_answer)\n",
    "    for batch in batch_text(text, GPT_CHAR_LIMIT/2-cum_char_count):\n",
    "        gpt.add_question(batch)\n",
    "        translation += gpt.get_response().get('choices')[0].get('message').get('content')\n",
    "    return translation\n",
    "get_batched_gpt_response(translated,system_prompt,test_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Performance and Speed, Free up to 2M Chars\n",
    "def get_azure_translation(text:str, api_key=AZURE_KEY) -> str:\n",
    "    translation = ''\n",
    "    key = api_key\n",
    "    endpoint = \"https://api.cognitive.microsofttranslator.com/\"\n",
    "    location = \"eastus\"\n",
    "    path = '/translate'\n",
    "    constructed_url = endpoint + path\n",
    "    params = {'api-version': '3.0','from': 'es','to': ['en']}\n",
    "    headers = {'Ocp-Apim-Subscription-Key': key,'Ocp-Apim-Subscription-Region': location,'Content-type': 'application/json','X-ClientTraceId': str(uuid.uuid4())}\n",
    "    for batch in batch_text(text, AZURE_CHAR_LIMIT):\n",
    "        body = [{'text': batch}]\n",
    "        request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "        translation += request.json()[0].get('translations')[0].get('text')\n",
    "    return translation\n",
    "#get_azure_translation(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast and Free, Stringent Limitations\n",
    "def get_mymemory_translation(text:str) -> str:\n",
    "    translation = ''\n",
    "    for batch in batch_text(text, 500):\n",
    "        translation += Translator(provider='mymemory',from_lang='es',to_lang='en').translate(batch)\n",
    "    return translation\n",
    "#get_mymemory_translation(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fastest and Native, Reduced Performance\n",
    "def get_offline_translation(text:str) -> str:\n",
    "    return argostranslate.translate.translate(text,'es', 'en')\n",
    "#get_offline_translation(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "# Thanks GPT\n",
    "def split_mp3(input_file_path:str, max_file_size_mb:int=20, output_folder:str=\"output\"):\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_clip = AudioFileClip(input_file_path)\n",
    "    total_duration = audio_clip.duration  # Total duration of the audio file in seconds\n",
    "    \n",
    "    # Assume an average bitrate for MP3 files (in bps)\n",
    "    # This may need to be adjusted based on the file's actual bitrate\n",
    "    avg_bitrate = 128000  # 128 kbps\n",
    "\n",
    "    # Calculate the maximum duration of each audio chunk in seconds\n",
    "    max_chunk_duration = (max_file_size_mb * 8 * 1024 * 1024) / avg_bitrate\n",
    "    \n",
    "    # Calculate the number of chunks that will be created\n",
    "    number_of_chunks = math.ceil(total_duration / max_chunk_duration)\n",
    "    \n",
    "    # Split the audio file into chunks\n",
    "    for i in range(number_of_chunks):\n",
    "        start_time = i * max_chunk_duration\n",
    "        end_time = min((i + 1) * max_chunk_duration, total_duration)\n",
    "        chunk = audio_clip.subclip(start_time, end_time)\n",
    "        \n",
    "        # Generate the output file path\n",
    "        output_file_path = os.path.join(output_folder, f\"chunk_{i+1}.mp3\")\n",
    "        \n",
    "        # Write the audio chunk to a file\n",
    "        chunk.write_audiofile(output_file_path, bitrate='128k')\n",
    "        \n",
    "        print(f\"Chunk {i+1}/{number_of_chunks} has been created: {output_file_path}\")\n",
    "    \n",
    "    audio_clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  54%|█████▍    | 15605/28902 [1:26:14<00:05, 2275.89it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in pm.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  54%|█████▍    | 15605/28902 [1:26:24<00:05, 2275.89it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in output/chunk_1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/xhk/Documents/iep-poc/sandbox.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m video \u001b[39m=\u001b[39m VideoFileClip(\u001b[39m'\u001b[39m\u001b[39mpm.mp4\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m video\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39mwrite_audiofile(\u001b[39m'\u001b[39m\u001b[39mpm.mp3\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m split_mp3(\u001b[39m'\u001b[39;49m\u001b[39mpm.mp3\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/home/xhk/Documents/iep-poc/sandbox.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X14sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     output_file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_folder, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mchunk_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.mp3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# Write the audio chunk to a file\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     chunk\u001b[39m.\u001b[39;49mwrite_audiofile(output_file_path, bitrate\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m128k\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mChunk \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnumber_of_chunks\u001b[39m}\u001b[39;00m\u001b[39m has been created: \u001b[39m\u001b[39m{\u001b[39;00moutput_file_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X14sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m audio_clip\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m<decorator-gen-63>:2\u001b[0m, in \u001b[0;36mwrite_audiofile\u001b[0;34m(self, filename, fps, nbytes, buffersize, codec, bitrate, ffmpeg_params, write_logfile, verbose, logger)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAttribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m\u001b[39m not set\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m f(clip, \u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mk)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/audio/AudioClip.py:206\u001b[0m, in \u001b[0;36mAudioClip.write_audiofile\u001b[0;34m(self, filename, fps, nbytes, buffersize, codec, bitrate, ffmpeg_params, write_logfile, verbose, logger)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMoviePy couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find the codec associated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mwith the filename. Provide the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcodec\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mparameter in write_audiofile.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m \u001b[39mreturn\u001b[39;00m ffmpeg_audiowrite(\u001b[39mself\u001b[39;49m, filename, fps, nbytes, buffersize,\n\u001b[1;32m    207\u001b[0m                          codec\u001b[39m=\u001b[39;49mcodec, bitrate\u001b[39m=\u001b[39;49mbitrate,\n\u001b[1;32m    208\u001b[0m                          write_logfile\u001b[39m=\u001b[39;49mwrite_logfile, verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    209\u001b[0m                          ffmpeg_params\u001b[39m=\u001b[39;49mffmpeg_params,\n\u001b[1;32m    210\u001b[0m                          logger\u001b[39m=\u001b[39;49mlogger)\n",
      "File \u001b[0;32m<decorator-gen-27>:2\u001b[0m, in \u001b[0;36mffmpeg_audiowrite\u001b[0;34m(clip, filename, fps, nbytes, buffersize, codec, bitrate, write_logfile, verbose, ffmpeg_params, logger)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAttribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m\u001b[39m not set\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m f(clip, \u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mk)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/audio/io/ffmpeg_audiowriter.py:166\u001b[0m, in \u001b[0;36mffmpeg_audiowrite\u001b[0;34m(clip, filename, fps, nbytes, buffersize, codec, bitrate, write_logfile, verbose, ffmpeg_params, logger)\u001b[0m\n\u001b[1;32m    160\u001b[0m logger(message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMoviePy - Writing audio in \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m filename)\n\u001b[1;32m    161\u001b[0m writer \u001b[39m=\u001b[39m FFMPEG_AudioWriter(filename, fps, nbytes, clip\u001b[39m.\u001b[39mnchannels,\n\u001b[1;32m    162\u001b[0m                             codec\u001b[39m=\u001b[39mcodec, bitrate\u001b[39m=\u001b[39mbitrate,\n\u001b[1;32m    163\u001b[0m                             logfile\u001b[39m=\u001b[39mlogfile,\n\u001b[1;32m    164\u001b[0m                             ffmpeg_params\u001b[39m=\u001b[39mffmpeg_params)\n\u001b[0;32m--> 166\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m clip\u001b[39m.\u001b[39miter_chunks(chunksize\u001b[39m=\u001b[39mbuffersize,\n\u001b[1;32m    167\u001b[0m                               quantize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    168\u001b[0m                               nbytes\u001b[39m=\u001b[39mnbytes, fps\u001b[39m=\u001b[39mfps,\n\u001b[1;32m    169\u001b[0m                               logger\u001b[39m=\u001b[39mlogger):\n\u001b[1;32m    170\u001b[0m     writer\u001b[39m.\u001b[39mwrite_frames(chunk)\n\u001b[1;32m    172\u001b[0m writer\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/audio/AudioClip.py:85\u001b[0m, in \u001b[0;36mAudioClip.iter_chunks\u001b[0;34m(self, chunksize, chunk_duration, fps, quantize, nbytes, logger)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39massert\u001b[39;00m(size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m chunksize)\n\u001b[1;32m     84\u001b[0m tt \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m\u001b[39m/\u001b[39mfps)\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39marange(pospos[i], pospos[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m---> 85\u001b[0m \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_soundarray(tt, nbytes\u001b[39m=\u001b[39;49mnbytes, quantize\u001b[39m=\u001b[39;49mquantize,\n\u001b[1;32m     86\u001b[0m                             fps\u001b[39m=\u001b[39;49mfps, buffersize\u001b[39m=\u001b[39;49mchunksize)\n",
      "File \u001b[0;32m<decorator-gen-62>:2\u001b[0m, in \u001b[0;36mto_soundarray\u001b[0;34m(self, tt, fps, quantize, nbytes, buffersize)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAttribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m\u001b[39m not set\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m f(clip, \u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mk)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/audio/AudioClip.py:127\u001b[0m, in \u001b[0;36mAudioClip.to_soundarray\u001b[0;34m(self, tt, fps, quantize, nbytes, buffersize)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39melif len(tt)> 1.5*buffersize:\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m    nchunks = int(len(tt)/buffersize+1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m                      for ttc in tt_chunks])\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m#print tt.max() - tt.min(), tt.min(), tt.max()\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m snd_array \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_frame(tt)\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m quantize:\n\u001b[1;32m    130\u001b[0m     snd_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmaximum(\u001b[39m-\u001b[39m\u001b[39m0.99\u001b[39m, np\u001b[39m.\u001b[39mminimum(\u001b[39m0.99\u001b[39m, snd_array))\n",
      "File \u001b[0;32m<decorator-gen-29>:2\u001b[0m, in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/decorators.py:89\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     85\u001b[0m new_a \u001b[39m=\u001b[39m [fun(arg) \u001b[39mif\u001b[39;00m (name \u001b[39min\u001b[39;00m varnames) \u001b[39melse\u001b[39;00m arg\n\u001b[1;32m     86\u001b[0m          \u001b[39mfor\u001b[39;00m (arg, name) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(a, names)]\n\u001b[1;32m     87\u001b[0m new_kw \u001b[39m=\u001b[39m {k: fun(v) \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m varnames \u001b[39melse\u001b[39;00m v\n\u001b[1;32m     88\u001b[0m          \u001b[39mfor\u001b[39;00m (k,v) \u001b[39min\u001b[39;00m kw\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m---> 89\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49mnew_a, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kw)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/Clip.py:93\u001b[0m, in \u001b[0;36mClip.get_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[39mreturn\u001b[39;00m frame\n\u001b[1;32m     92\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_frame(t)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/Clip.py:136\u001b[0m, in \u001b[0;36mClip.fl.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    133\u001b[0m     apply_to \u001b[39m=\u001b[39m []\n\u001b[1;32m    135\u001b[0m \u001b[39m#mf = copy(self.make_frame)\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m newclip \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_make_frame(\u001b[39mlambda\u001b[39;00m t: fun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_frame, t))\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m keep_duration:\n\u001b[1;32m    139\u001b[0m     newclip\u001b[39m.\u001b[39mduration \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/Clip.py:187\u001b[0m, in \u001b[0;36mClip.fl_time.<locals>.<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m apply_to \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     apply_to \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 187\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfl(\u001b[39mlambda\u001b[39;00m gf, t: gf(t_func(t)), apply_to,\n\u001b[1;32m    188\u001b[0m                keep_duration\u001b[39m=\u001b[39mkeep_duration)\n",
      "File \u001b[0;32m<decorator-gen-29>:2\u001b[0m, in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/decorators.py:89\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     85\u001b[0m new_a \u001b[39m=\u001b[39m [fun(arg) \u001b[39mif\u001b[39;00m (name \u001b[39min\u001b[39;00m varnames) \u001b[39melse\u001b[39;00m arg\n\u001b[1;32m     86\u001b[0m          \u001b[39mfor\u001b[39;00m (arg, name) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(a, names)]\n\u001b[1;32m     87\u001b[0m new_kw \u001b[39m=\u001b[39m {k: fun(v) \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m varnames \u001b[39melse\u001b[39;00m v\n\u001b[1;32m     88\u001b[0m          \u001b[39mfor\u001b[39;00m (k,v) \u001b[39min\u001b[39;00m kw\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m---> 89\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49mnew_a, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kw)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/Clip.py:93\u001b[0m, in \u001b[0;36mClip.get_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[39mreturn\u001b[39;00m frame\n\u001b[1;32m     92\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_frame(t)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/audio/io/AudioFileClip.py:77\u001b[0m, in \u001b[0;36mAudioFileClip.__init__.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader\u001b[39m.\u001b[39mduration\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffersize \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader\u001b[39m.\u001b[39mbuffersize\n\u001b[0;32m---> 77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_frame \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m t: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreader\u001b[39m.\u001b[39;49mget_frame(t)\n\u001b[1;32m     78\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnchannels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader\u001b[39m.\u001b[39mnchannels\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/audio/io/readers.py:186\u001b[0m, in \u001b[0;36mFFMPEG_AudioReader.get_frame\u001b[0;34m(self, tt)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_around(fr_min)\n\u001b[1;32m    183\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\n\u001b[1;32m    184\u001b[0m             (fr_max \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_startframe)\n\u001b[1;32m    185\u001b[0m                  \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer)):\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuffer_around(fr_max)\n\u001b[1;32m    188\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(tt),\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnchannels))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/audio/io/readers.py:240\u001b[0m, in \u001b[0;36mFFMPEG_AudioReader.buffer_around\u001b[0;34m(self, framenumber)\u001b[0m\n\u001b[1;32m    238\u001b[0m     conserved \u001b[39m=\u001b[39m current_f_end \u001b[39m-\u001b[39m new_bufferstart \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    239\u001b[0m     chunksize \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffersize\u001b[39m-\u001b[39mconserved\n\u001b[0;32m--> 240\u001b[0m     array \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_chunk(chunksize)\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer[\u001b[39m-\u001b[39mconserved:], array])\n\u001b[1;32m    242\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/audio/io/readers.py:113\u001b[0m, in \u001b[0;36mFFMPEG_AudioReader.read_chunk\u001b[0;34m(self, chunksize)\u001b[0m\n\u001b[1;32m    111\u001b[0m chunksize \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(chunksize))\n\u001b[1;32m    112\u001b[0m L \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnchannels\u001b[39m*\u001b[39mchunksize\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnbytes\n\u001b[0;32m--> 113\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproc\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mread(L)\n\u001b[1;32m    114\u001b[0m dt \u001b[39m=\u001b[39m {\u001b[39m1\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mint8\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m2\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mint16\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m4\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mint32\u001b[39m\u001b[39m'\u001b[39m}[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnbytes]\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(np, \u001b[39m'\u001b[39m\u001b[39mfrombuffer\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "video = VideoFileClip('pm.mp4')\n",
    "video.audio.write_audiofile('pm.mp3')\n",
    "split_mp3('pm.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"output\"\n",
    "\n",
    "# List all the files in the output directory\n",
    "file_list = os.listdir(output_folder)\n",
    "transcribed_text = ''\n",
    "response = None\n",
    "\n",
    "# Loop through the files and read them with MoviePy\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith(\".mp3\"):  # Check if the file is an MP3\n",
    "        file_path = os.path.join(output_folder, file_name)\n",
    "        response = openai.Audio.transcribe('whisper-1', file=open(file_path,'rb'),api_key=GPT_API_KEY)\n",
    "        transcribed_text += response.get('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_text = get_offline_translation(transcribed_text)\n",
    "with open('parent_meeting.txt','w') as f:\n",
    "    f.write(dual_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, your messages resulted in 4172 tokens. Please reduce the length of the messages.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/xhk/Documents/iep-poc/sandbox.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m response \u001b[39m=\u001b[39m get_batched_gpt_response(dual_text, system_prompt)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m response\n",
      "\u001b[1;32m/home/xhk/Documents/iep-poc/sandbox.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m batch_text(text, GPT_CHAR_LIMIT\u001b[39m-\u001b[39mcum_char_count):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     gpt\u001b[39m.\u001b[39madd_question(batch)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     translation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m gpt\u001b[39m.\u001b[39;49mget_response()\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mreturn\u001b[39;00m translation\n",
      "\u001b[1;32m/home/xhk/Documents/iep-poc/sandbox.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_response\u001b[39m(\u001b[39mself\u001b[39m): \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X20sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessages\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xhk/Documents/iep-poc/sandbox.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, your messages resulted in 4172 tokens. Please reduce the length of the messages."
     ]
    }
   ],
   "source": [
    "response = get_batched_gpt_response(dual_text, system_prompt, test_prompts)\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
