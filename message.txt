Yes, having the digital version of the blank form can indeed help in processing filled-out forms more accurately after they've been scanned. By comparing the filled-out form with the blank template, you can better identify which areas of the form contain user-entered data, including the content within complex tables and the status of checkboxes.

Here is a possible Python solution that involves several steps and tools:

1. **Pre-processing the Scanned Image**: Before applying OCR, itâ€™s often beneficial to pre-process the image to improve OCR accuracy. This may include steps such as noise reduction, binarization (converting to black and white), and rotation to the correct orientation.

2. **OCR Processing**: Use an OCR library such as Tesseract to extract text from the form. While OCR is not always perfect with complex tables and checkboxes, it can serve as a starting point.

3. **Template Matching**: Compare the scanned form with the digital blank form. This step can help to identify the regions of the form that have been filled out. You can use image processing libraries such as OpenCV for template matching to find the position of known elements (like checkboxes or table headers).

4. **Data Extraction**: For checkboxes, instead of relying on OCR, you can use image processing techniques to detect filled checkboxes by comparing the differences between the blank form and the filled form. For tables, you can use the positions of the headers to determine cell boundaries.

5. **Post-processing**: After extraction, you may need to post-process the data, such as validating the format of the extracted data, or mapping extracted checkbox states to Boolean values.

Below is a high-level outline of a Python script using libraries such as `PIL` for image manipulation, `pytesseract` for OCR, and `OpenCV` for template matching:

```python
from PIL import Image
import pytesseract
import cv2
import numpy as np

# Preprocess the image
def preprocess_image(image_path):
    image = cv2.imread(image_path)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # Apply binarization, noise reduction, etc.
    # ...
    return gray

# Use OCR to extract text
def extract_text(image):
    custom_config = r'--oem 3 --psm 6'  # Example config
    text = pytesseract.image_to_string(image, config=custom_config)
    return text

# Use template matching to find checkboxes and tables
def match_template(image, template):
    method = cv2.TM_CCOEFF_NORMED
    res = cv2.matchTemplate(image, template, method)
    # Process the results to find locations
    # ...

# Detect checkboxes by comparing the scanned form to the blank form
def detect_checkboxes(filled_image, blank_image):
    # Perform image subtraction or other methods to find differences
    # ...

# Main process
def process_form(scanned_image_path, blank_form_path):
    # Load and preprocess images
    scanned_image = preprocess_image(scanned_image_path)
    blank_form = preprocess_image(blank_form_path)
    
    # Extract text from the scanned image
    extracted_text = extract_text(scanned_image)
    
    # Find positions of checkboxes and tables
    checkboxes = match_template(scanned_image, blank_form)  # You would need actual checkbox templates
    checkbox_states = detect_checkboxes(scanned_image, blank_form)
    
    # Output the structured data
    # ...

    return extracted_text, checkbox_states

# Example usage
scanned_image_path = 'path/to/scanned/form.jpg'
blank_form_path = 'path/to/blank/form.jpg'
extracted_text, checkbox_states = process_form(scanned_image_path, blank_form_path)
```

This code is a simplified example. The actual implementation will need to be more robust and handle various scenarios and image qualities. You might need to refine image pre-processing and post-processing steps according to the specific characteristics of the forms you are working with.

For checkboxes, you may simply detect filled squares by comparing the intensity of pixels in the region of the checkbox against the blank form. A filled checkbox will typically have a different pixel intensity distribution compared to an empty one.

For tables, defining the location of table cells in the blank form and mapping the extracted text to these locations can be a strategy. Open-source libraries like `pdfplumber` (if the form is a PDF) can also be used for more structured extraction of text from tables.

It's also important to note that if your form is very complex or if the OCR's accuracy is crucial for your application, you might want to consider a commercial OCR tool or service that specializes in form extraction and provides more sophisticated algorithms for dealing with complex layouts and elements such as checkboxes.